{
  "logoType": "default",
  "logo": {
    "lucideIcon": "",
    "imagePath": "",
    "imageLink": ""
  },
  "logoScale": 1.2,
  "iconColorType": "default",
  "wordmark": "Obsidian",
  "customFont": "interfaceFont",
  "fontSize": "4em",
  "fontColorType": "default",
  "fontWeight": 600,
  "maxResults": 5,
  "showStarredFiles": false,
  "showRecentFiles": true,
  "maxRecentFiles": 5,
  "storeRecentFile": true,
  "showPath": true,
  "selectionHighlight": "default",
  "showShortcuts": true,
  "markdownOnly": false,
  "unresolvedLinks": false,
  "recentFilesStore": [
    {
      "filepath": "source/_posts/科研学习/论文总结/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.md",
      "timestamp": 1736873590873
    },
    {
      "filepath": "source/_posts/科研学习/论文总结/Chain-of-Thought Reasoning Without Prompting.md",
      "timestamp": 1736873029560
    }
  ],
  "starredFileStore": [],
  "searchDelay": 0,
  "replaceNewTabs": true,
  "newTabOnStart": true,
  "closePreviousSessionTabs": true,
  "omnisearch": true
}