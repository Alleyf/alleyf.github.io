---
title: DL概念知识库
date: 2024-04-06 22:46:30
tags: 
sticky: 60
excerpt: 
author: fcs
index_img: https://picsum.photos/800/250
lang: zh-CN
theme: default
_class: lead
paginate: true
backgroundColor: 
backgroundImage: url('https://marp.app/assets/hero-background.svg')
number headings: auto, first-level 1, max 5, start-at 1, 1.1
---

![](https://picsum.photos/800/250)

# 1 logits

模型的 logits 是模型在训练过程中输出的**原始预测值（Tensor张量）**，它们是`模型最后一层（通常是 softmax 层）之前的输出`。在自然语言处理（NLP）中，logits 通常是一个实数向量，其**长度等于模型词汇表的大小**。每个元素在向量中对应一个词汇表中的词，并表示模型预测该词作为下一个词的概率。

$$
logits：[0.1, 0.2, 0.3, ...]-->soft(logits)=[0.05, 0.1, 0.15, ...]
$$
在 softmax 函数应用于 logits 之后，会得到一个概率分布，其中每个元素代表相应词汇表中的词作为下一个输出词的概率。具体来说，softmax 函数会将 logits 转换为概率，使得这些概率的总和为 1。这样，每个输出位置上的概率分布可以被解释为模型对于下一个词的预测。


# 2 贪婪解码

贪婪解码（Greedy Decoding）是自然语言处理中一种常见的解码策略，尤其是在使用大型语言模型（如循环神经网络RNN、长短期记忆网络LSTM、Transformer等）进行文本生成任务时。这种解码方法的核心思想是在每个时间步骤中，选择具有最高概率的单词作为输出，从而构建出一个完整的序列。 ^956a45

### 2.1.1 贪婪解码的步骤

1. **初始化**：开始时，模型接收一个起始符号（如句子的开始标记`<s>`）作为输入。
2. **预测第一个词**：模型基于起始符号预测下一个词的概率分布。
3. **选择最高概率词**：从概率分布中选择概率最高的词作为输出序列的第一个词。
4. **迭代过程**：将已选择的词添加到输出序列的末尾，并将其作为下一步的上下文输入模型，重复预测下一个词。
5. **终止条件**：当模型输出一个结束符号（如句子的结束标记`</s>`）或者达到预设的最大长度时，解码过程结束。

### 2.1.2 贪婪解码的特点

- **简单高效**：贪婪解码算法实现简单，计算效率高，因为它在每个时间步骤中只选择一个最佳选项。
- **确定性**：解码过程是确定性的，相同的输入总是产生相同的输出序列。
- **缺乏灵活性**：由于贪婪解码在每个步骤中只考虑单一的最佳选项，它可能无法捕捉到序列中的多样性和复杂性。

### 2.1.3 贪婪解码的局限性

- **子优化**：贪婪解码可能导致子优化问题，即在局部步骤中选择最佳词，但这些选择可能不会导致整体上最佳的序列。
- **缺乏全局观**：贪婪解码没有考虑整个序列的可能性，可能忽略了其他可能更好的序列。

在某些情况下，为了克服贪婪解码的局限性，研究者们开发了其他更复杂的解码策略，如束搜索（Beam Search）和采样（Sampling）等，这些方法能够在解码过程中考虑多个候选词，从而提高生成序列的多样性和质量。