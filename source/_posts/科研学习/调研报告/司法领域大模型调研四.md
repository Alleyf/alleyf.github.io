---
title: 司法领域KG-LLM调研四
date: 2023-11-07 13:08:27
tags:
  - NLP
  - KG
sticky: 85
excerpt: some overview about law KG and LLM。
author: 范财胜
---
![](https://picsum.photos/800/250)

# 调研任务

1. 将各个关键点搜索相关文献进行总结。
2. 调研关于司法领域的KG与LLM相互作用的文献，有则加之，无责阐述与司法相关的关系作为创新点。

# 知识图谱与事理图谱

![image.png](http://qnpicmap.fcsluck.top/pics/202311221126003.png)

# 知识图谱增强大模型


## 1.KG强化LLM预训练
知识图谱通常包含从高度可信的来源进行提取、处理并经过人工评估审查的信息。LLM仅使用单独的自然语言文本可能导致信息覆盖范围有限，因此，来自知识图谱的结构化显式信息可以被融入到LLM预训练语料库中，从而提高LLM的可靠性与泛化性能，有助于解决大模型的幻觉问题。为此国内外学者对此方向进行多种研究。
1. [Fedor Moiseev](https://aclanthology.org/2022.naacl-main.113.pdf)提出了一种通过直接在知识图谱（KG）的事实三元组上训练 T5 模型来将KG结构化知识注入LLM的方法。此方法在 Wikidata KG 上预训练的模型优于 FreebaseQA 和 WikiHop 上的 T5 基线，在管理训练数据时不需要知识图谱和文本语料库之间的对齐，有助于处理行业规模的知识图。
2. [Cicero Nogueira dos Santos](https://arxiv.org/pdf/2210.04726.pdf)我们提出了一种训练软提示的新方法，通过使用同一组 KP 来提高 LM 在三个不同任务中的性能：问答、事实检查和关系分类，从而证明了以实体为中心的 KP 可以被视为一种通用的知识库嵌入方法，可用于扩展 LM 的世界知识。
3. 将外部特定领域知识（例如 UMLS）注入预训练语言模型 (LM) 可以提高其处理专业领域内任务的能力，[刘方宇](https://aclanthology.org/2021.acl-short.72.pdf)提出了一种有效的迁移学习方案，利用通用领域翻译来提高领域专业表示模型的跨语言能力解决了将特定领域知识从资源丰富的语言转移到资源贫乏的语言的挑战。
4. [Barlas Oguz](https://aclanthology.org/2022.findings-naacl.115.pdf)提出 UniK-QA统一结构化和非结构化信息源的预训练LLM在生成和QA任务上性能有所提高。 
5. [Pat Verga](https://aclanthology.org/2021.naacl-main.288.pdf)通过将向量表示的可解释性神经符号知识库在预训练和微调期间增强到LLM，显著强化了模型在知识密集型QA任务中的性能。



## 2.KG微调更新LLM
有许多研究运用知识图谱来拓展和优化提示生成，相较于传统的手工方法，这种方式在提示数量、质量和多样性方面都有显著的增加。
2. [侯越先](https://aclanthology.org/2021.emnlp-main.355.pdf)整合KG等外部显示知识帮助提示工程，尤其是通过提供实体的附加上下文（例如属性、Khop 邻居），以帮助 LLM 生成更好的预测。  
3. [张宁豫](https://dl.acm.org/doi/10.1145/3485447.3511998)使用 KnowPrompt 这样的方法将KG中关系标签之间的语义和先验知识合并到关系提取的提示调整中，增强提示构建过程并通过结构化约束优化其表示。
4. 可以通过 KG 2 Instruction技术将知识图谱的转化成指令用于微调，[叶宏彬](https://arxiv.org/pdf/2301.11332.pdf)通过OntoPrompt将本体用于提示微调。
5. [Yoonjoo Lee](https://dl.acm.org/doi/10.1145/3491102.3502087)凭借有意义的学习模式和KG的大量遍历路径的支持，实现低成本KG单轮和多轮脚手架提示。
6. [Siyuan Cheng](https://arxiv.org/pdf/2301.10405.pdf)提出编辑 KGE 模型允许直接修改LLM的知识以适应特定任务，从而提高编辑过程的效率和准确性，并且 KGE 能在不影响整体性能的情况下更新特定事实进而更新LLM。
7. [Nicola De Cao](http://export.arxiv.org/pdf/2104.08164v1.pdf)提出通过知识图谱的三元组对大语言模型进行编辑从而实现知识更新，[Mojtaba Nayyeri](https://export.arxiv.org/pdf/2208.02743v3.pdf)将大语言模型跟知识图谱通过表示学习进行融合。

## 3.KG增强LLM推理和可解释性
事实上，研究表明，从通用数据集训练中获得的知识主要是关于流行实体的。然而，对于特定领域的知识，可能有一些LLM尚未可知的潜在的重要知识，包括无法纳入LLM的私人和业务关键知识。LLM可以通过检索增强方法来获取外部知识，从而解决知识中断的问题。知识图谱可以表示和生成思维链，将知识从大模型中解耦出来，通过结构化更好的思维链提升大模型的推理和可解释能力，可以对医疗、法律等专精垂域知识库上的可解释推理问答提供新思路。
1. [崔家喜](https://arxiv.org/pdf/2306.16092.pdf)使用外挂知识库的方式增强大模型输出的效果，将用户输入的问题放入知识库中进行检索，并将相关的文档片段取出后与原始输入问题进行合并等操作后，将其作为新的输入送入大模型中，这样能够减轻 LLM 输出的“幻觉”问题。
2. [鄂海红](https://arxiv.org/abs/2310.08975)在利用大模型强大的学习能力以及自然语言理解能力的同时，利用知识图谱的准确性和可解释性来弥补了大模型可能的幻觉现象以及本身的黑盒短板，将知识从大模型中解耦出来，实现可解释推理问答的LLM+KG新范式。
3. [Wang-Chiew Tan](https://arxiv.org/pdf/2306.01061.pdf)整合不同的显性知识，包括非结构化知识（例如段落）和结构化知识（例如知识图谱和数据库），以增强LLM，实现半参数LLM。
4. [Xingxuan Li](https://arxiv.org/abs/2305.13269)提出了知识链(CoK-Li)，它通过查询生成器从知识库获取结构化知识来执行知识引导推理。
5. [Jianing Wang](https://arxiv.org/abs/2306.06427) 还从知识库中检索结构化知识。它从事实性和忠实性方面估计推理链，并提示模型重新思考不可靠的推理，从而减轻 CoK-Li 中的知识检索错误。 
6. [Keheng Wang](https://arxiv.org/abs/2308.13259)提出KD-CoT通过多轮 QA 方法解决事实推理问题。他们设计了一个反馈增强检索器，用于检索每轮 QA 中的相关外部知识，以校准推理过程。





# 大模型增强知识图谱



## 1.LLM辅助KG自动建模

1. [Wenxuan Zhou](https://aclanthology.org/2022.acl-long.371.pdf)提出了一个统一的预训练多语言表示模型 Prix-LM ，用于多语言知识库的构建和完成，通过随意的LM 目标进行训练，利用单语言知识三元组和跨语言链接，它将不同语言的知识库中的知识嵌入到共享的表示空间中，这有利于在语言之间转移互补知识，可以捕获、传播和丰富多语言知识库中的知识。


## 2.LLM促进KG融合更新
1. [Shibo Hao](https://export.arxiv.org/pdf/2206.14268v3.pdf)提出了一种应用GPT-3的方法，以输入实体对和手动种子提示自动生成一个加权的提示 en- semble。然后，再次使用PLM进行搜索，并将排名靠前的实体对与集合体进行配对，以使KG完成补全。
2. [Pengcheng Jiang](https://arxiv.org/pdf/2305.15597.pdf)提出 TAGREAL，它自动生成高质量的查询提示并从大型文本语料库中检索支持信息，以探测 PLM 中的知识以完成知识图谱补全。



## 3.LLM增强KG知识表示

1. [Jiho Kim](https://arxiv.org/abs/2310.11220.pdf)提出了 KG-GPT，这是一个利用 LLM 来完成使用 KG 的任务的多功能框架。 KG-GPT 通过句子分割、图检索和推理三个步骤分别用于分割句子、检索相关图组件和得出逻辑结论，该模型表现出较强竞争力和稳健的性能，甚至优于几个完全监督的模型。



# 高价值参考文献

```cardlink
url: https://mp.weixin.qq.com/s?__biz=MzU2NjAxNDYwMg==&mid=2247502129&idx=1&sn=e76b15365f6c95c8a414732f32f6e130&chksm=fcb06ed4cbc7e7c28f8a21c213bc7f56d2d95ff9363aefaa3125476f402e3775a0f3e40c58c3&scene=178&cur_album_id=3073566525166419969#rd
title: "“新KG”视点 | 陈华钧——大模型时代的知识处理：新机遇与新挑战"
description: "OpenKG大模型专辑：本期刊载浙江大学计算机学院陈华钧教授的文章——“大模型时代的知识处理：新机遇与新挑战”"
host: mp.weixin.qq.com
image: https://mmbiz.qpic.cn/sz_mmbiz_jpg/GNpj5fw72EoyxMRIDvcFd4PZChBQzOEqZEExEickoA9MnnoiblBZoWibDnA7JpMeZnibN8Jl9bCLkLQ9Xia38xf8PNQ/0?wx_fmt=jpeg
```
[微信公众平台](https://mp.weixin.qq.com/s?__biz=MzU2NjAxNDYwMg==&mid=2247502129&idx=1&sn=e76b15365f6c95c8a414732f32f6e130&chksm=fcb06ed4cbc7e7c28f8a21c213bc7f56d2d95ff9363aefaa3125476f402e3775a0f3e40c58c3&scene=178&cur_album_id=3073566525166419969#rd)


# 评测基准

司法大模型综合评价方法：

```cardlink
url: https://paperswithcode.com/paper/a-comprehensive-evaluation-of-large-language-1
title: "Papers with Code - A Comprehensive Evaluation of Large Language Models on Legal Judgment Prediction"
description: "Implemented in one code library."
host: paperswithcode.com
image: https://raw.githubusercontent.com/srhthu/lm-compeval-legal/master/resources/static/fig_setting_example_v2.jpg
```
1. [A Comprehensive Evaluation of Large Language Models on Legal Judgment Prediction | Papers With Code](https://paperswithcode.com/paper/a-comprehensive-evaluation-of-large-language-1)

```cardlink
url: https://paperswithcode.com/paper/legalbench-a-collaboratively-built-benchmark
title: "Papers with Code - LegalBench: A Collaboratively Built Benchmark for Measuring Legal Reasoning in Large Language Models"
description: "🏆 SOTA for Legal Reasoning on LegalBench (Rule-recall) (Balanced Accuracy metric)"
host: paperswithcode.com
image: https://production-media.paperswithcode.com/thumbnails/paper/2308.11462.jpg
```
2. [LegalBench: A Collaboratively Built Benchmark for Measuring Legal Reasoning in Large Language Models | Papers With Code](https://paperswithcode.com/paper/legalbench-a-collaboratively-built-benchmark)


# 个人总结

> 以上均为KG与LLM相互增强的部分国内外研究现状，目前尚未调研到有关司法领域的KG与LLM相互增强协同运用的研究，只是提到可以将两者结合运用到司法领域，但是已有部分企业做了相关产品，如[LLMs+知识图谱！Spotlight领域大模型产品发布加速公安智能化](https://www.msn.cn/zh-cn/news/other/llms-%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1-spotlight%E9%A2%86%E5%9F%9F%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BA%A7%E5%93%81%E5%8F%91%E5%B8%83%E5%8A%A0%E9%80%9F%E5%85%AC%E5%AE%89%E6%99%BA%E8%83%BD%E5%8C%96/ar-AA1juWnn)

```cardlink
url: https://www.brightendata.cn/product/spotlight
title: "悦点科技-让数据创造价值"
description: "悦点科技是国内领先的企业级数据分析和数据平台服务软件企业，利用数据编织（Data Fabric）和知识图谱（Knowledge Graph）技术帮助客户构建知识图谱和数据分析平台，链接各类异构数据，挖掘数据内在价值，让数据更好的用于决策"
host: www.brightendata.cn
favicon: /favicon.ico
```
1. [悦点科技-让数据创造价值](https://www.brightendata.cn/product/spotlight)

```cardlink
url: https://www.gongdao.com/coretech.html?page=intelligence
title: "共道科技-专业的法律科技服务商"
description: "共道网络科技有限公司（简称：共道科技）于2018年成立于浙江杭州，是由阿里巴巴集团和杭州市城投集团共同设立的的互联网科技公司。公司通过应用互联网、云计算、区块链、机器智能等技术，为法院和市场监督管理局等司法和行政执法部门提供数智化解决方案，并为金融企业、知识产权权利人等企业级客户提供一站式纠纷解决等法律服务。"
host: www.gongdao.com
```
2. [共道科技-专业的法律科技服务商](https://www.gongdao.com/coretech.html?page=intelligence)