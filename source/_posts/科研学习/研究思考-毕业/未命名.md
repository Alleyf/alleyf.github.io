### 关键点
- **研究进展显著**：基于LLM的时序知识图谱（Temporal Knowledge Graph, TKG）推理已从传统深度学习方法转向LLM增强模型，证据显示LLM能有效捕捉时序模式，但仍需结合图结构以减少幻觉。
- **可解释性提升**：现有方法通过规则生成和链式推理（如Chain-of-History）提供可追踪的推理路径，研究表明这能改善模型透明度，但对复杂时序依赖的解释仍存在争议。
- **挑战与不确定性**：虽然LLM在零样本设置下表现优异，但数据噪声和知识更新可能导致偏差，建议采用动态适应策略以平衡准确性和可解释性。

### 引言
时序知识图谱推理涉及利用历史数据预测未来事实，而LLM的集成为其注入了语义理解能力。早期工作依赖图神经网络，但LLM如GPT-4的出现，使得推理更具灵活性，同时增强可解释性。

### 主要方法概述
常见方法包括LLM引导的规则生成和动态适应，如LLM-DA框架，通过提取时序逻辑规则实现可解释推理。链式历史推理（CoH）则逐步探索高阶历史链，融合LLM与图模型，提升预测精度。

### 挑战与未来方向
主要挑战包括LLM的时序幻觉和知识更新成本。未来研究可聚焦混合框架，结合LLM的语义优势与KG的结构严谨性。

---

基于LLM的时序知识图谱推理与可解释性增强研究是一个新兴交叉领域，结合了大型语言模型（Large Language Models, LLMs）的语义理解能力与时序知识图谱（Temporal Knowledge Graphs, TKGs）的动态结构表示。该领域旨在解决传统TKG推理方法（如图神经网络或强化学习）在可解释性和适应性方面的局限性，通过LLM注入外部知识，提升推理准确性和透明度。本综述首先概述TKG基础与LLM集成背景，然后讨论关键方法、应用、可解释性增强策略，最后分析挑战与未来方向。综述基于近期代表性工作，按时间和主题逻辑组织引用。

#### 时序知识图谱基础与LLM集成背景
时序知识图谱（TKGs）将静态知识图谱扩展为四元组形式（主体、关系、客体、时间戳），用于捕捉现实世界中事实的演化，如政治事件或人物关系变化[1]。传统TKG表示学习（TKGRL）方法分为变换基（如TTransE）、分解基（如TComplEx）和图神经网络基（如TEA-GNN），这些方法擅长建模时序依赖，但缺乏语义深度和可解释性[2]。LLM的兴起（如GPT系列和Llama模型）提供了解决方案：LLM通过预训练捕捉广泛知识，并在零样本或少样本设置下进行时序推理[3]。例如，LLM可通过提示工程分析历史数据，生成时序逻辑规则，从而弥补TKG的稀疏性[4]。

LLM与TKG的集成主要分为三类：KG增强LLM（使用TKG注入知识以减少LLM幻觉）、LLM增强KG（利用LLM构建或预测TKG事实）和混合框架[5]。在时序场景中，这种集成特别有效，因为LLM能处理知识演化，而TKG提供结构化时序约束。调研显示，LLM在TKG预测中的应用从2023年开始激增，相关论文超过50篇[6]。

#### 关键方法与技术
早期方法聚焦LLM的零样本推理，如ICLTKG通过上下文学习从历史事实中预测未来事件，而无需监督训练[7]。然而，这些方法仅限于一阶历史，忽略高阶依赖。为此，Chain-of-History (CoH) 推理提出逐步探索高阶历史链：首先从一阶历史中推断重要事实，然后构建二阶或更高阶链，并使用指数衰减评分融合LLM与图模型输出[8]。实验在ICEWS数据集上显示，CoH提升MRR 2-5%，证明LLM的语义理解能补充图模型的结构局限。

另一代表性框架是LLM-guided Dynamic Adaptation (LLM-DA)，它利用LLM分析历史数据提取时序逻辑规则，并通过动态适应策略更新规则以适应TKG演化[4]。具体而言，LLM-DA包括四个阶段：时序逻辑规则采样（使用约束马尔可夫随机游走）、规则生成（输入top-k相关关系到LLM生成高覆盖规则）、动态适应（使用置信度更新低质量规则）和候选推理（结合规则基与图基推理）。该方法无需微调LLM，在ICEWS和GDELT数据集上显著提升准确率，提供可解释的规则路径。

在代理框架方面，Time-aware ReAct Agent (TempAgent) 扩展ReAct范式，集成时序检索工具处理多粒度约束（如日、月、年）[3]。TempAgent通过迭代的“思考-行动-观察”循环过滤无关事实，并在MultiTQ基准上实现41.3%的改进。类似地，EvoReasoner结合多路径分解和时序上下文全局初始化，进行多跳推理，同时使用EvoKG模块通过置信基矛盾解决更新TKG[9]。

其他方法包括GenTKG（检索增强生成用于时序预测）和zrLLM（零样本关系学习，通过LLM生成关系描述并结合关系历史学习器）[10,11]。这些方法强调LLM的生成能力，但需结合GNN以处理噪声。

#### 应用场景
基于LLM的TKG推理广泛应用于时序知识图谱补全（TKGC）和预测（TKG Forecasting）。在补全中，LLM通过语义增强（如实体描述）改善内插任务[2]。在预测中，混合方法如CoH融合LLM链式推理与图嵌入，实现外推[8]。此外，在TKG问题回答（TKGQA）中，TempAgent处理复杂查询，如“Richard Boucher在2008年12月访问伊拉克后第一个访问的国家”，通过时序过滤分解子任务[3]。

实体对齐和多模态应用也是热点：如TEA-GNN使用时序注意力对齐不同TKG[2]。调研显示，这些应用在新闻、金融和医疗领域有潜力，但需处理知识更新[5]。

#### 可解释性增强策略
可解释性是该领域核心挑战，因为LLM常被视为黑箱。现有方法通过规则基和路径追踪增强透明度。例如，LLM-DA生成的时序逻辑规则（如“president_of ← occupation_of ∧ politician_of”）提供可追踪推理，支持解释[4]。CoH通过步步可视化历史链（如粗体一阶、蓝色二阶），并生成自然语言解释，提升用户信任[8]。

解释基方法分为子图推理（如xERTE迭代采样邻居构建子图）和强化学习（如CluSTeR使用RL搜索线索）[2]。LLM增强这些方法：如LMExplainer使用图注意力网络识别LLM决策信号，并转换为自然语言[12]。此外，注意力可视化和因果解释（如在QA-GNN中权重节点路径）进一步改善[5]。实验表明，这些策略在复杂查询中减少幻觉，但对时序偏差的解释仍需优化。

#### 挑战与未来方向
尽管进展显著，该领域面临挑战：(1) LLM幻觉和时序分布偏移，可能导致错误预测[9]；(2) 计算开销，微调LLM资源密集[4]；(3) 数据噪声和知识过时，需要动态更新如EvoKG[9]；(4) 可解释性与准确性的权衡，高阶推理可能牺牲透明度[8]。

未来方向包括：(1) 开发更高效的混合框架，如将LLM作为代理指导TKG演化[3]；(2) 融入多模态LLM处理时序图像/视频KG[5]；(3) 强调少样本和零样本学习，减少依赖标注数据[7]；(4) 通过注意力机制和可视化提升解释[2]；(5) 探索伦理问题，如偏差缓解和隐私保护[6]。总体而言，该领域正向更鲁棒、可信的AI系统演进。

#### 表1: 关键方法比较
| 方法       | LLM集成方式          | 时序处理          | 可解释性机制              | 性能提升（示例）       | 局限性                  |
|------------|----------------------|-------------------|---------------------------|-------------------------|-------------------------|
| LLM-DA    | 规则生成与动态适应  | 约束随机游走     | 时序逻辑规则路径         | ICEWS上MRR+10%        | 依赖top-k关系选择      |
| CoH       | 链式历史推理        | 高阶历史链探索   | 步步可视化与NL解释       | ICEWS18上MRR+5%       | 重载历史信息风险        |
| TempAgent | ReAct代理框架       | 多粒度时序过滤   | 迭代轨迹追踪             | MultiTQ上Hits@1 70%   | 复杂多跳查询挑战        |
| EvoReasoner | 多路径分解与更新   | 时序上下文初始化 | 置信基矛盾解决           | 动态QA上匹配671B模型 | 计算密集                |

#### 表2: 数据集与基准
| 数据集    | 描述                       | 应用场景          | 引用来源 |
|-----------|----------------------------|-------------------|----------|
| ICEWS14  | 国际事件时序事实           | 预测与QA         | [4,8]   |
| MultiTQ  | 多粒度时序问题回答         | TKGQA            | [3]     |
| GDELT    | 全球事件数据库             | 预测             | [2]     |
| CronQuestions | 时序KGQA基准            | 问题回答         | [3]     |

本综述强调，基于LLM的TKG推理与可解释性增强正从理论向实际应用转型，未来需更多实证研究验证其泛化性。

**Key Citations:**
- [1] Bollacker, K., et al. (2008). Freebase: a collaboratively created graph database for structuring human knowledge. SIGMOD.
- [2] Ji, S., et al. (2024). A Survey on Temporal Knowledge Graph: Representation Learning and Applications. arXiv:2403.04782.
- [3] Sun, J., et al. (2025). Time-aware ReAct Agent for Temporal Knowledge Graph Question Answering. NAACL Findings.
- [4] Wang, J., et al. (2024). Large Language Models-guided Dynamic Adaptation for Temporal Knowledge Graph Reasoning. NeurIPS.
- [5] Kau, A., et al. (2024). Combining Knowledge Graphs and Large Language Models. arXiv:2407.06564.
- [6] Pan, S., et al. (2024). Unifying large language models and knowledge graphs: A roadmap. IEEE TKDE.
- [7] Lee, S., et al. (2023). Temporal knowledge graph forecasting without knowledge using in-context learning. arXiv:2305.10613.
- [8] Luo, R., et al. (2024). Chain-of-History Reasoning for Temporal Knowledge Graph Forecasting. ACL Findings.
- [9] Hong, J., et al. (2025). Temporal Reasoning over Evolving Knowledge Graphs. arXiv:2509.15464.
- [10] Chen, L., et al. (2024). GenTKG: Generative Forecasting on Temporal Knowledge Graph with Large Language Models. NAACL Findings.
- [11] Ding, N., et al. (2023). Zero-shot relational learning on temporal knowledge graphs with large language models. arXiv:2311.10112.
- [12] Creswell, A., et al. (2022). Selection-inference: Exploiting large language models for interpretable logical reasoning. arXiv:2205.09712.