---
title: 深度学习论文阅读总结
date: 2023-10-03-15:36
tags:
  - NLP
sticky: 85
excerpt: some overview about NLP papers。
---
| 序号  | 作者               | 来源                |                                                          标题                                                           | 关键词                           | 研究对象      | 主要实验方法        | 结论                             | 阅读日期                |
| :-: | ---------------- | ----------------- | :-------------------------------------------------------------------------------------------------------------------: | ----------------------------- | --------- | ------------- | ------------------------------ | ------------------- |
|  1  | Kaiming He       | 2015-CVPR         |                                   [[Deep residual learning for image recognition]]                                    | 深度神经网络，残差，短接                  | 网络深度      | 提出层之间跳跃短接的残差块 | 解决深层网络退化问题，并提升了网络效果，是后续深层网络的基石 | 2023-08-10 16:06:07 |
|  2  | Ashish Vaswani   | 2017-NIPS         |                                            [[Attention is All you Need  ]]                                            | Transformer，注意力机制，编码器，解码器     | 网络架构，特称提取 |               |                                |                     |
|  3  | Haiyan Zhao .etc | 2023-11-28-arxive | [Explainability for large language models A survey](Explainability%20for%20large%20language%20models%20A%20survey.md) | LLM,<br>CoT,<br>Explainablity |           |               |                                |                     |
|  4  |                  |                   |                                                                                                                       |                               |           |               |                                |                     |
|  5  |                  |                   |                                                                                                                       |                               |           |               |                                |                     |
|  6  |                  |                   |                                                                                                                       |                               |           |               |                                |                     |
|  7  |                  |                   |                                                                                                                       |                               |           |               |                                |                     |

