#### 论文标题

**Exploring the Limits of Domain-Adaptive Training for Detoxifying Large-Scale Language Models**

#### 作者

Boxin Wang, Wei Ping, Chaowei Xiao, Peng Xu, Mostofa Patwary, Mohammad Shoeybi, Bo Li, Anima Anandkumar, Bryan Catanzaro

#### 会议

36th Conference on Neural Information Processing Systems (NeurIPS 2022)

### 1. 研究背景

大规模预训练语言模型（LMs）在各种自然语言处理（NLP）任务中表现出色，但这些模型可能会生成有毒和有偏见的语言，引发伦理问题。为了减少语言模型的毒性，研究者们提出了多种方法，包括解码时方法、预训练方法和领域适应性训练方法。领域适应性训练通过在精心策划的数据集上微调预训练模型来减少毒性，这种方法比解码时方法更灵活，比预训练方法更高效。

### 2. 研究方法

#### 2.1 训练语料

- **SGEAT（Self-Generation Enabled domain-Adaptive Training）**：利用语言模型的生成能力创建非毒性训练语料。
  - **提示构造**：设计不同的提示来引导模型生成训练语料。
  - **自我生成**：使用提示生成最多1000个词的文本。
  - **数据过滤**：使用Perspective API过滤掉有毒样本，保留最非毒性的50%文本。
  - **领域适应性训练**：使用过滤后的非毒性语料进行模型微调。

#### 2.2 模型规模

- 研究了从126M到530B参数规模的模型，发现：
  - 不同规模的模型在相同的预训练语料上表现出相似的毒性水平。
  - 大规模模型需要更多的努力来减少毒性，例如更大的训练语料和更多的微调周期。

#### 2.3 参数高效训练

- **适配器（Adapter）**：在每个Transformer层添加瓶颈投影层，初始化为接近零以提高训练稳定性。
- **前缀调优（Prefix Tuning）**：在输入中添加连续的“前缀”向量以更好地引导模型生成。

### 3. 实验结果

#### 3.1 训练语料的影响

- **SGEAT（增强版）**在1.3B模型上实现了最低的毒性分数，同时PPL（困惑度）略有增加，且未降低模型在下游任务上的性能。
- **SGEAT（增强版）**在使用更小的训练语料（100k样本）时，仍然比DAPT（使用7500k样本）表现出更低的毒性。

#### 3.2 模型规模的影响

- **SGEAT**在不同规模的模型上均表现出更好的毒性减少效果，即使使用更小的训练语料。
- **530B模型**需要更多的训练周期和更大的训练语料来实现类似的毒性减少效果。

#### 3.3 参数高效训练的影响

- **适配器**在大规模模型（8.3B和530B）上表现出更好的参数效率，同时减少了PPL的增加和提高了下游任务的准确性。
- **前缀调优**在减少毒性方面效果有限，且对PPL的控制不如适配器。

### 4. 人类评估

- 人类评估结果与自动评估结果（Perspective API）高度一致，确认了不同规模的模型具有相似的毒性水平，且大规模模型更难 detoxify。

### 5. 讨论

#### 5.1 对边缘群体的偏见

- 使用BOLD数据集评估了1.3B标准模型和SGEAT（增强版）模型在性别和种族领域的PPL，发现SGEAT在减少毒性的同时，对性别和种族偏见的影响较小。

#### 5.2 SGEAT的局限性

- SGEAT依赖于Perspective API来过滤有毒样本，但现有的毒性分类器可能存在偏见，影响SGEAT的效果。
- 预训练模型本身可能已经存在偏见，这可能影响自生成语料的质量和 detoxification 的效果。

### 6. 结论

本文通过系统地研究领域适应性训练在减少大规模语言模型毒性方面的极限，提出了SGEAT方法，实现了数据高效和有效的 detoxification。研究还发现，适配器在大规模模型上提供了更好的参数效率和模型性能。未来的工作将集中在减少预训练模型的社会偏见，以及开发更 robust、无偏见的仇恨言论检测器。

### 7. 未来工作

- **减少社会偏见**：开发新的方法来减少预训练模型中的社会偏见。
- **改进仇恨言论检测器**：设计更 robust、无偏见的仇恨言论检测器，以提高 detoxification 的效果。