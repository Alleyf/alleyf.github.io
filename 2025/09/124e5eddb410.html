

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="http://qnpicmap.fcsluck.top/pics/202311162214229.png">
  <link rel="icon" href="http://qnpicmap.fcsluck.top/pics/202311162214229.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
    <meta http-equiv="Content-Security-Policy" content="upgrade-insecure-requests">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="alleyf">
  <meta name="keywords" content="">
  
    <meta name="description" content="TKG研究选题推荐与规划结合大语言模型的少样本时间知识图谱推理与可解释性增强研究✅选题理由 1.1 价值与意义 该选题旨在解决少样本和可解释性两大核心挑战，这对于您所拥有的社科科研管理数据尤为重要。这类数据通常具有关系稀疏、实体更新频繁的特点，难以用传统方法进行有效建模和预测。本研究的价值在于：  解决稀疏数据难题：社科领域项目、人员、成果等数据通常不平衡，很多实体和关系只出现极少数次（即长尾分布">
<meta property="og:type" content="article">
<meta property="og:title" content="alleyf">
<meta property="og:url" content="https://alleyf.github.io/2025/09/124e5eddb410.html">
<meta property="og:site_name" content="alleyf">
<meta property="og:description" content="TKG研究选题推荐与规划结合大语言模型的少样本时间知识图谱推理与可解释性增强研究✅选题理由 1.1 价值与意义 该选题旨在解决少样本和可解释性两大核心挑战，这对于您所拥有的社科科研管理数据尤为重要。这类数据通常具有关系稀疏、实体更新频繁的特点，难以用传统方法进行有效建模和预测。本研究的价值在于：  解决稀疏数据难题：社科领域项目、人员、成果等数据通常不平衡，很多实体和关系只出现极少数次（即长尾分布">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2025-09-22T13:27:34.247Z">
<meta property="article:modified_time" content="2025-09-22T14:53:51.119Z">
<meta property="article:author" content="alleyf">
<meta name="twitter:card" content="summary_large_image">
  
  
    <meta name="referrer" content="no-referrer-when-downgrade">
  
  
  <title>alleyf</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"alleyf.github.io","root":"/","version":"1.9.2","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":true,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"follow_dnt":true,"baidu":"d57048846da607439cf11718741f2eb0","google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml"};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  

  
    <!-- Baidu Analytics -->
    <script async>
      if (!Fluid.ctx.dnt) {
        var _hmt = _hmt || [];
        (function() {
          var hm = document.createElement("script");
          hm.src = "https://hm.baidu.com/hm.js?d57048846da607439cf11718741f2eb0";
          var s = document.getElementsByTagName("script")[0];
          s.parentNode.insertBefore(hm, s);
        })();
      }
    </script>
  

  

  

  

  

  

  



  
<!-- hexo injector head_end start --><script> let HEXO_MMEDIA_DATA = { js: [], css: [], aplayerData: [], metingData: [], artPlayerData: [], dplayerData: []}; </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.0.0"><link rel="alternate" href="/atom.xml" title="alleyf" type="application/atom+xml">
</head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Mr.Alleyf</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/gallery/">
                <i class="iconfont icon-images"></i>
                画廊
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/atom.xml">
                <i class="iconfont icon-rss"></i>
                RSS
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" target="_blank" rel="noopener" href="https://github.com/Alleyf">
                <i class="iconfont icon-github-fill"></i>
                Github
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/links/">
                <i class="iconfont icon-link-fill"></i>
                友链
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('https://api.likepoems.com/img/nature') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text=""></span>
          
        </div>

        
          
  <div class="mt-3">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-author" aria-hidden="true"></i>
        alleyf
      </span>
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2025-09-22 21:27" pubdate>
          2025年9月22日 晚上
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          14k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          118 分钟
        
      </span>
    

    
    
      
        <span id="busuanzi_container_page_pv" style="display: none">
          <i class="iconfont icon-eye" aria-hidden="true"></i>
          <span id="busuanzi_value_page_pv"></span> 次
        </span>
        
      
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none"></h1>
            
              <p class="note note-info">
                
                  
                    本文最后更新于：9 天前
                  
                
              </p>
            
            
              <div class="markdown-body">
                
                <h2 id="TKG研究选题推荐与规划"><a href="#TKG研究选题推荐与规划" class="headerlink" title="TKG研究选题推荐与规划"></a>TKG研究选题推荐与规划</h2><h3 id="结合大语言模型的少样本时间知识图谱推理与可解释性增强研究✅"><a href="#结合大语言模型的少样本时间知识图谱推理与可解释性增强研究✅" class="headerlink" title="结合大语言模型的少样本时间知识图谱推理与可解释性增强研究✅"></a>结合大语言模型的少样本时间知识图谱推理与可解释性增强研究✅</h3><h4 id="选题理由"><a href="#选题理由" class="headerlink" title="选题理由"></a>选题理由</h4><hr>
<p><strong>1.1 价值与意义</strong></p>
<p>该选题旨在解决少样本和可解释性两大核心挑战，这对于您所拥有的<strong>社科科研管理数据</strong>尤为重要。这类数据通常具有<strong>关系稀疏、实体更新频繁</strong>的特点，难以用传统方法进行有效建模和预测。本研究的价值在于：</p>
<ul>
<li><strong>解决稀疏数据难题</strong>：社科领域项目、人员、成果等数据通常不平衡，很多实体和关系只出现极少数次（即<strong>长尾分布</strong>问题）。本选题通过少样本学习方法，能够让模型从有限的样本中快速学习并泛化到新出现的项目或人员上，提高数据利用效率和模型泛化能力。</li>
<li><strong>提升模型可信度</strong>：在科研管理、政策分析等高风险、高价值场景中，需要<strong>透明、可追溯</strong>的决策依据。本研究通过引入可解释性机制，能清晰地展示模型做出预测的逻辑路径，例如“因为A教授在2020年获得过国家级奖励，所以他更有可能在2025年申请到国家重点项目”。这不仅能增加用户信任，也为决策者提供了有力的支持。</li>
</ul>
<p><strong>1.2 创新点</strong></p>
<ul>
<li><strong>大语言模型驱动的少样本推理框架</strong>：将LLM的强大<strong>语义理解能力</strong>与TKG的<strong>结构化知识</strong>相结合。LLM可以从项目名称、人员简介等文本描述中提取丰富的语义信息，弥补结构化数据稀疏性的不足，从而增强少样本场景下的推理能力。</li>
<li><strong>混合式可解释性机制</strong>：设计一种结合<strong>神经符号方法</strong>的混合式可解释性框架。一方面，利用<strong>注意力机制</strong>（Attention Mechanism）等神经网络方法定位关键的历史事实；另一方面，通过LLM将这些事实转换成人类可读的<strong>自然语言推理路径</strong>，实现从“黑盒”到“灰盒”甚至“白盒”的转变。</li>
<li><strong>通用型解决方案</strong>：提出的方法<strong>不依赖特定领域</strong>，可应用于公开数据集（如ICEWS系列）进行通用模型验证，再迁移到您的社科科研管理数据上进行应用验证，展示其普适性。</li>
</ul>
<p><strong>1.3 贡献</strong></p>
<ul>
<li>提出一种新型的少样本TKGC模型，有效解决数据稀疏和长尾分布问题，提升模型在未见实体&#x2F;关系上的预测精度。</li>
<li>设计一种混合式可解释性框架，为TKG推理提供透明、可追溯的解释，填补该领域在可信度方面的空白。</li>
<li>验证LLM在融合TKG结构信息和语义信息方面的潜力，为未来TKG与LLM的深度融合提供新思路。</li>
</ul>
<p><strong>1.4 基线模型</strong></p>
<ul>
<li><strong>少样本学习</strong>：MetaTKGR (2022)，FTAG (2022)，MOST (2022)，TFSC (2023)。</li>
<li><strong>LLM融合</strong>：zrLLM (2023)，TKG-LM (2023)，COH (2024)。</li>
</ul>
<p><strong>1.5 技术方案</strong></p>
<ol>
<li><p><strong>数据预处理与表示</strong>：将结构化事实（<code>h, r, t, τ</code>）与非结构化文本（如项目简介、人员经历）进行对齐，构建<strong>时序知识图谱</strong>。使用预训练LLM对文本进行编码，获取丰富的语义嵌入。</p>
</li>
<li><p><strong>核心模型设计</strong>：</p>
<ul>
<li><strong>模块一：少样本学习模块</strong>。采用元学习（Meta-Learning）框架，训练模型从少数历史事实中快速学习新实体和关系的表示。</li>
<li><strong>模块二：LLM增强推理模块</strong>。设计一个轻量级适配器（Adapter），将TKG的结构嵌入与LLM的语义嵌入进行融合。在推理时，利用LLM生成<strong>候选路径</strong>，再由TKG模型进行评分。</li>
<li><strong>模块三：可解释性模块</strong>。利用LLM的指令遵循能力，将模型的推理路径（例如注意力权重高的事实序列）转化为自然语言解释。</li>
</ul>
</li>
<li><p><strong>预测与评估</strong>：针对<code>(h, r, ?, τ)</code>和<code>(? ,r, t, τ)</code>等少样本预测任务进行实验，评估<code>Hits@k</code>、<code>MRR</code>、<code>MR</code>等指标。</p>
</li>
</ol>
<p><strong>1.6 数据集</strong></p>
<ul>
<li><strong>公开数据集</strong>：ICEWS18、ICEWS05-15、GDELT。这些数据集可以用于模型训练和通用性验证。</li>
<li><strong>自制数据集</strong>：您的社科科研管理数据。用于在实际应用场景中验证模型的有效性和可解释性。</li>
</ul>
<p><strong>1.7 实验设计</strong></p>
<ul>
<li><strong>通用性验证</strong>：在ICEWS等公开数据集上，将您的模型与基线模型进行对比，证明其在少样本、长尾分布场景下的性能优势。</li>
<li><strong>应用场景验证</strong>：<ul>
<li><strong>任务</strong>：基于您的社科数据，设计两个具体的应用任务：<ol>
<li><strong>项目成果预测</strong>：预测新立项的项目在结题时可能产生的成果类型（如论文、专利、专著等）。</li>
<li><strong>专家合作推荐</strong>：根据特定主题，为新项目推荐潜在的合作专家。</li>
</ol>
</li>
<li><strong>评估</strong>：除了传统的指标，增加针对可解释性的<strong>人工评估</strong>，如用户对模型解释的满意度、解释的准确性等。</li>
</ul>
</li>
</ul>
<p><strong>1.8 预期结论</strong></p>
<ul>
<li>证明所提出的少样本学习框架在处理稀疏TKG数据上的优越性，显著提升<code>Hits@k</code>和<code>MRR</code>指标。</li>
<li>证明LLM融合策略有效提升了模型的语义理解和泛化能力。</li>
<li>证明可解释性模块能够生成准确、有用的自然语言解释，提升模型在高风险场景下的可信度。</li>
</ul>
<hr>
<h3 id="面向增量学习的动态时间知识图谱演化建模研究❌"><a href="#面向增量学习的动态时间知识图谱演化建模研究❌" class="headerlink" title="面向增量学习的动态时间知识图谱演化建模研究❌"></a>面向增量学习的动态时间知识图谱演化建模研究❌</h3><h4 id="选题理由-1"><a href="#选题理由-1" class="headerlink" title="选题理由"></a>选题理由</h4><hr>
<p><strong>2.1 价值与意义</strong></p>
<p>您拥有的社科科研管理数据是一个典型的<strong>动态、持续演化</strong>的图谱。项目、人员、成果等信息会随着时间的推移不断增加、修改甚至删除。该选题的价值在于：</p>
<ul>
<li><strong>解决知识遗忘难题</strong>：传统模型需要<strong>从头重训</strong>以适应新增数据，这不仅计算成本高昂，还可能导致对旧知识的<strong>灾难性遗忘</strong>。本研究通过增量学习，让模型能够高效地<strong>持续学习</strong>新知识，同时保持对旧知识的记忆。</li>
<li><strong>实时决策支持</strong>：在科研管理中，需要对最新的项目动态做出快速反应。增量学习模型可以实时更新知识，为项目审批、中期检查等提供最新的决策依据，提高管理效率。</li>
</ul>
<p><strong>2.2 创新点</strong></p>
<ul>
<li><strong>持续学习框架</strong>：设计一个适用于TKG的持续学习（Continual Learning）框架，通过<strong>知识蒸馏</strong>、<strong>经验回放</strong>等技术，解决增量学习中的灾难性遗忘问题。</li>
<li><strong>高效的图演化编码器</strong>：设计一种轻量级的图神经网络（GNN）编码器，能够快速、高效地处理新加入的图快照（graph snapshot），而不是处理整个历史图谱，显著降低计算复杂度。</li>
</ul>
<p><strong>2.3 贡献</strong></p>
<ul>
<li>构建首个针对TKG的增量学习框架，为动态知识图谱的实时更新和维护提供了一种通用且高效的解决方案。</li>
<li>通过实验证明所提方法能够有效缓解灾难性遗忘，在保持旧知识预测精度的同时，对新知识有良好的学习能力。</li>
<li>为实时演化的大规模TKG应用提供了理论基础和技术支持。</li>
</ul>
<p><strong>2.4 基线模型</strong></p>
<ul>
<li><strong>动态嵌入</strong>：TiRGN (2021)，RE-GCN (2021)。</li>
<li><strong>增量学习</strong>：无直接TKG增量学习基线，可参考持续学习领域的通用方法，并适配到TKG任务上。</li>
</ul>
<p><strong>2.5 技术方案</strong></p>
<ol>
<li><strong>增量式数据加载</strong>：将您的数据按时间顺序切分为连续的快照序列$G_1, G_2, …, G_t$。</li>
<li><strong>核心模型设计</strong>：<ul>
<li><strong>模块一：TKG编码器</strong>。使用轻量级的GNN对每个时间快照进行编码，得到实体和关系的嵌入表示。</li>
<li><strong>模块二：增量学习模块</strong>。<ul>
<li><strong>知识蒸馏</strong>：训练新模型时，使用旧模型的输出作为“软标签”，指导新模型学习，以保留旧知识。</li>
<li><strong>经验回放</strong>：存储一小部分旧数据作为“经验库”，在学习新数据时，同时用这些旧数据进行训练，防止遗忘。</li>
</ul>
</li>
<li><strong>模块三：LLM增强</strong>。在每次增量更新时，利用LLM对新出现的实体和关系进行语义编码，为模型提供额外的辅助信息。</li>
</ul>
</li>
</ol>
<p><strong>2.6 数据集</strong></p>
<ul>
<li><strong>公开数据集</strong>：ICEWS05-15，GDELT。这些数据集有较长的时间跨度，适合进行增量学习实验。</li>
<li><strong>自制数据集</strong>：您的社科科研管理数据。</li>
</ul>
<p><strong>2.7 实验设计</strong></p>
<ul>
<li><strong>增量学习任务</strong>：模拟真实场景，将数据集按时间顺序切分为若干个任务（Task）。例如，<code>T1: 2018数据</code>，<code>T2: 2019数据</code>，…</li>
<li><strong>评估指标</strong>：除了<code>MRR</code>等指标，重点关注<strong>遗忘率（Forgetting Rate）</strong>，即模型在学习新任务后，对旧任务表现下降的程度。</li>
</ul>
<p><strong>2.8 预期结论</strong></p>
<ul>
<li>证明所提出的增量学习框架能有效解决TKG在动态演化过程中的灾难性遗忘问题。</li>
<li>证明该方法在处理大规模、持续更新的TKG时，相比传统从头重训的方法，能显著提升训练效率，并保持较高的预测精度。</li>
</ul>
<hr>
<h3 id="基于大语言模型与神经符号融合的时间知识图谱复杂查询回答❌"><a href="#基于大语言模型与神经符号融合的时间知识图谱复杂查询回答❌" class="headerlink" title="基于大语言模型与神经符号融合的时间知识图谱复杂查询回答❌"></a>基于大语言模型与神经符号融合的时间知识图谱复杂查询回答❌</h3><h4 id="选题理由-2"><a href="#选题理由-2" class="headerlink" title="选题理由"></a>选题理由</h4><hr>
<p><strong>3.1 价值与意义</strong></p>
<p>本选题将重点放在<strong>应用层面</strong>，解决您的社科科研管理数据中<strong>复杂查询</strong>的难题。</p>
<ul>
<li><strong>多跳推理</strong>：例如，“在2020年后获得国家自然科学基金的专家中，谁在2023年之后发表了关于大数据分析的C刊论文？”这类问题需要多步推理，传统方法难以处理。</li>
<li><strong>时间逻辑</strong>：问题中通常包含复杂的<strong>时间约束</strong>，如“之前”、“之后”、“持续”、“在…期间”等，这对于仅能处理时间点的模型来说是巨大挑战。本研究通过结合LLM的语言理解和符号推理，可以精准地回答这类问题。</li>
</ul>
<p><strong>3.2 创新点</strong></p>
<ul>
<li><strong>神经符号框架</strong>：结合LLM强大的自然语言理解能力和符号逻辑的严谨推理能力。LLM负责将自然语言问题解析成<strong>结构化的逻辑查询</strong>，然后由符号推理引擎在TKG上执行查询，从而实现可解释、高精度的复杂查询回答。</li>
<li><strong>时间条件解析</strong>：专门设计模块，能够准确识别和解析自然语言问题中的时间逻辑，并将其转化为符号化表示，如时间区间、时间点关系等。</li>
</ul>
<p><strong>3.3 贡献</strong></p>
<ul>
<li>提出一种通用型的神经符号框架，有效解决TKG上的多跳、带时间约束的复杂查询回答问题。</li>
<li>为TKG与LLM的融合提供了一种新的技术路径，将各自的优势最大化，为高级应用（如智能问答、决策支持）奠定基础。</li>
</ul>
<p><strong>3.4 基线模型</strong></p>
<ul>
<li><strong>问答</strong>：CRONKGQA (2021)，TSQA (2022)。</li>
<li><strong>逻辑规则</strong>：TLogic (2022)，LLM-DA (2024)。</li>
</ul>
<p><strong>3.5 技术方案</strong></p>
<ol>
<li><strong>问题解析</strong>：利用LLM（例如GPT-4或Llama系列）将自然语言问题转化为一系列<strong>逻辑谓词</strong>和<strong>时间约束</strong>，例如<code>[find(p) where exists (e, r, t, τ) s.t. ...]</code>。</li>
<li><strong>符号推理</strong>：将解析后的逻辑查询输入到一个<strong>符号推理引擎</strong>中，该引擎在TKG上进行多跳遍历和时间约束匹配。</li>
<li><strong>答案生成</strong>：将推理结果（实体或时间戳）返回给LLM，由LLM将结果包装成自然语言回答。</li>
</ol>
<p><strong>3.6 数据集</strong></p>
<ul>
<li><strong>公开数据集</strong>：Wikidata (QA)。</li>
<li><strong>自制数据集</strong>：基于您的社科科研管理数据，手动或半自动生成一些复杂问答对。</li>
</ul>
<p><strong>3.7 实验设计</strong></p>
<ul>
<li><strong>评估</strong>：评估模型在<code>MRR</code>、<code>Hits@k</code>等传统指标上的表现，并特别关注回答的<strong>准确率</strong>和<strong>可解释性</strong>。</li>
<li><strong>消融实验</strong>：设计实验以验证LLM、符号推理引擎等不同模块对模型性能的贡献。</li>
</ul>
<p><strong>3.8 预期结论</strong></p>
<ul>
<li>证明所提出的神经符号框架在处理带时间条件的复杂查询上，相比纯神经网络方法有显著优势。</li>
<li>证明该框架可以有效提升问答的准确性和可解释性，为社科科研管理提供高效的智能问答工具。</li>
</ul>
<hr>
<h3 id="融合大语言模型与知识图谱的少样本时序事件预测研究✅"><a href="#融合大语言模型与知识图谱的少样本时序事件预测研究✅" class="headerlink" title="融合大语言模型与知识图谱的少样本时序事件预测研究✅"></a>融合大语言模型与知识图谱的少样本时序事件预测研究✅</h3><p><strong>选题理由</strong></p>
<p>这个选题将你的优势（社科管理数据）与主流前沿技术（LLM、少样本学习）相结合，具有显著的创新性和实用价值。</p>
<ul>
<li><p><strong>价值与意义：</strong> 你的社科管理数据具有时间维度，但关系稀疏。传统的知识图谱模型难以有效处理这种<strong>长尾分布</strong>和<strong>数据稀疏</strong>问题。将LLM的强大<strong>语义理解</strong>能力与TKG的<strong>结构化知识</strong>相结合，可以从文本描述中提取更多有用的语义信息，从而在<strong>少样本</strong>场景下更好地预测科研项目的未来动态，如项目成果、人员变动等。这对于科研管理部门进行智能决策、风险预警和资源分配具有重要意义。</p>
</li>
<li><p><strong>创新点：</strong></p>
<ol>
<li><strong>混合模型架构：</strong> 提出一种新颖的、通用的<strong>混合模型架构</strong>，结合<strong>预训练大语言模型</strong>（用于语义理解）和<strong>图神经网络</strong>（用于结构建模）。这种架构可以在不依赖大量历史数据的情况下，通过LLM的<strong>零样本&#x2F;少样本学习</strong>能力，对新的实体或关系进行有效预测。</li>
<li><strong>时间感知提示：</strong> 设计一种<strong>时间感知的提示工程</strong>（prompt engineering），将时间戳、历史事件序列和实体&#x2F;关系描述以自然语言形式输入LLM，使其能够更好地理解事件的<strong>时序逻辑</strong>和<strong>演化模式</strong>。</li>
<li><strong>可解释性增强：</strong> 利用LLM的<strong>可解释性</strong>优势，通过生成自然语言的<strong>推理路径</strong>或<strong>决策依据</strong>，解释模型为什么做出特定预测。这能解决传统黑盒模型在高风险场景中<strong>缺乏信任</strong>的问题。</li>
</ol>
</li>
<li><p><strong>贡献：</strong></p>
<ol>
<li>验证并提出一种针对<strong>少样本、数据稀疏TKG</strong>的有效解决方案，该方案在你的社科数据上具有很好的通用性。</li>
<li>为LLM与TKG的深度融合提供一个新的<strong>技术框架</strong>，特别是针对<strong>少样本时间推理</strong>任务。</li>
<li>提供一种<strong>可解释性</strong>强的模型，为科研管理等高风险决策场景提供可信赖的预测工具。</li>
</ol>
</li>
<li><p><strong>基线模型（Baseline）：</strong></p>
<ul>
<li><p><strong>LLM-DA (NeurIPS 2024)：</strong> 一种基于LLM的逻辑规则学习方法，能够进行可解释的多跳推理。</p>
</li>
<li><p><strong>zrLLM (Chen et al., 2023)：</strong> 一种利用LLM进行零样本TKG预测的方法，通过将历史事实序列化为提示来预测未来事件。</p>
</li>
<li><p><strong>MetaTKGR (Park et al., 2022)：</strong> 一种基于元学习的TKG补全模型，专门用于解决新实体&#x2F;关系的少样本问题。</p>
</li>
</ul>
</li>
<li><p><strong>模型设计：</strong></p>
<ol>
<li><p><strong>数据预处理：</strong> 将结构化数据转换为<strong>事实序列</strong>（如：“项目A在2024年获得立项”）。对于实体&#x2F;关系，可引入其文本描述（如“项目A：关于人工智能在教育领域的应用研究”）。</p>
</li>
<li><p><strong>模型一（密集数据场景）：</strong> 在公开数据集（如ICEWS18）上，采用<strong>LLM + GNN</strong>的混合模型。LLM用于提供<strong>实体&#x2F;关系嵌入</strong>的初始语义信息，然后GNN（如RE-GCN）聚合邻居信息并捕捉<strong>时序演化模式</strong>。</p>
</li>
<li><p><strong>模型二（少样本场景）：</strong> 在你的社科数据上，采用基于<strong>提示学习</strong>（Prompt Learning）的LLM模型，并辅以少量示例进行<strong>上下文学习</strong>（In-Context Learning）。<strong>不依赖于GNN</strong>的复杂结构，而是将<strong>时间事实</strong>和<strong>历史信息</strong>构建为文本提示，直接利用LLM进行推理。</p>
</li>
</ol>
</li>
<li><p><strong>数据集：</strong></p>
<ul>
<li><p><strong>公开数据集：</strong> ICEWS18 或 ICEWS05-15，用于验证模型在<strong>数据密集</strong>场景下的通用性和有效性。</p>
</li>
<li><p><strong>自制数据集：</strong> 你的社科科研管理数据，用于验证模型在<strong>数据稀疏、少样本</strong>场景下的实际应用效果。</p>
</li>
</ul>
</li>
<li><p><strong>实验设计：</strong></p>
<ul>
<li><p><strong>对比实验：</strong> 在两个数据集上，将你的模型与上述基线模型进行对比，评估<strong>Hits@k</strong>、<strong>MRR</strong>和<strong>MR</strong>等核心指标。</p>
</li>
<li><p><strong>消融实验：</strong> 分析模型中LLM、GNN、时间提示等不同模块的贡献，验证各部分的有效性。</p>
</li>
<li><p><strong>可解释性分析：</strong> 定性分析模型生成的推理路径，并与人类专家判断进行对比，展示其解释的合理性。</p>
</li>
</ul>
</li>
<li><p><strong>预期结论：</strong> 你的模型将在少样本和数据稀疏的TKG上表现出优于传统方法的性能，尤其在处理<strong>未见实体&#x2F;关系</strong>时，并且能够提供<strong>可信赖</strong>的推理过程。</p>
</li>
</ul>
<hr>
<h3 id="基于时序知识图谱与语言模型协同增强的动态事件预测与归因研究❌"><a href="#基于时序知识图谱与语言模型协同增强的动态事件预测与归因研究❌" class="headerlink" title="基于时序知识图谱与语言模型协同增强的动态事件预测与归因研究❌"></a>基于时序知识图谱与语言模型协同增强的动态事件预测与归因研究❌</h3><p><strong>选题理由</strong></p>
<p>此选题更侧重于<strong>动态</strong>和<strong>因果归因</strong>，强调模型对事件演化的理解，并利用LLM进行更深层次的<strong>语义归因</strong>，契合你的管理数据中项目“立项→变更→结项”的<strong>流程演化</strong>特性。</p>
<ul>
<li><p><strong>价值与意义：</strong> 你的数据不仅包含项目事实，更包含了项目整个生命周期的动态演化。传统的TKG模型擅长预测未来事件，但往往难以解释<strong>为什么</strong>会发生某个事件。该选题旨在利用LLM的语义理解能力，不仅预测“项目A明年会获得奖项”，还能进一步归因“因为项目A在今年有重要的技术突破和人员变动”。这对于深入分析项目成败原因、优化管理流程具有重大价值。</p>
</li>
<li><p><strong>创新点：</strong></p>
<ol>
<li><p><strong>归因机制：</strong> 提出一种<strong>事件归因</strong>模块，通过LLM分析历史事件序列，识别导致未来事件发生的<strong>关键时序路径</strong>或<strong>因果链</strong>。例如，识别“项目成员变动”与“项目结项时间推迟”之间的关联。</p>
</li>
<li><p><strong>动态关系表示：</strong> 传统TKG关系是静态的，而此模型将关系视为动态的，其语义和强度随时间演化。例如，“合作”关系可能从“弱合作”演变为“核心合作”。</p>
</li>
<li><p><strong>协同推理框架：</strong> 构建一个<strong>LLM-TKG协同推理框架</strong>，其中GNN负责捕捉<strong>结构演化</strong>，LLM负责进行<strong>语义推理</strong>和<strong>归因</strong>，两者相互增强，共同完成预测任务。</p>
</li>
</ol>
</li>
<li><p><strong>贡献：</strong></p>
<ol>
<li><p>提出了TKG预测任务的新维度：<strong>事件归因</strong>，从“预测”走向“解释”。</p>
</li>
<li><p>为处理具有复杂<strong>时序依赖</strong>和<strong>因果关系</strong>的动态数据提供了一种新的、通用的解决方案。</p>
</li>
<li><p>在科研管理等垂直领域，为提供<strong>流程分析</strong>和<strong>决策支持</strong>工具奠定基础。</p>
</li>
</ol>
</li>
<li><p><strong>基线模型（Baseline）：</strong></p>
<ul>
<li><p><strong>TLogic (Liu et al., 2022)：</strong> 基于逻辑规则进行时间推理，提供一定的可解释性。</p>
</li>
<li><p><strong>TGL-LLM (Xiong et al., 2024)：</strong> 融合图模型和LLM的框架，用于增强时序推理。</p>
</li>
<li><p><strong>DREAM (Wu et al., 2023)：</strong> 基于强化学习的方法，将TKG补全建模为序列决策问题。</p>
</li>
</ul>
</li>
<li><p><strong>模型设计：</strong></p>
<ol>
<li><p><strong>模型一（事件预测）：</strong> 专注于<strong>外推任务</strong>。采用融合<strong>动态嵌入</strong>和<strong>LLM</strong>的架构。动态嵌入模块（如DE-SimplE）用于捕捉实体和关系的动态演化规律，LLM则作为<strong>语义增强器</strong>，为新实体&#x2F;关系提供初始语义，并辅助预测。</p>
</li>
<li><p><strong>模型二（事件归因）：</strong> 在模型一的基础上增加<strong>归因模块</strong>。当模型预测某个事件时，LLM会分析与该事件相关的历史事实序列，并生成一段自然语言的解释。这个模块可以借鉴强化学习（如DREAM）或<strong>注意力机制</strong>（如TEA-GNN）的思想，定位关键历史事实。</p>
</li>
</ol>
</li>
<li><p><strong>数据集：</strong> 同选题一，使用ICEWS系列公开数据集和你的社科管理数据。</p>
</li>
<li><p><strong>实验设计：</strong></p>
<ul>
<li><p><strong>预测性能：</strong> 在两个数据集上对比你的模型与基线模型在<strong>Hits@k</strong>等指标上的表现。</p>
</li>
<li><p><strong>归因效果：</strong> 设计一套定量和定性的评估方法。例如，使用人工标注的<strong>归因路径</strong>作为黄金标准，评估模型生成的解释与黄金标准的重合度。</p>
</li>
</ul>
</li>
<li><p><strong>预期结论：</strong> 模型不仅能在预测准确性上超越传统方法，还能有效地识别和解释事件之间的时序依赖和因果关系，为决策提供更深层次的洞察。</p>
</li>
</ul>
<hr>
<h3 id="面向时序知识图谱的持续增量学习与LLM知识融合研究（✅：模型1）"><a href="#面向时序知识图谱的持续增量学习与LLM知识融合研究（✅：模型1）" class="headerlink" title="面向时序知识图谱的持续增量学习与LLM知识融合研究（✅：模型1）"></a>面向时序知识图谱的持续增量学习与LLM知识融合研究（✅：模型1）</h3><p><strong>选题理由</strong></p>
<p>你的社科管理数据是<strong>持续更新</strong>的，新项目、新人员、新成果不断涌现。该选题聚焦于<strong>增量学习</strong>，解决模型<strong>知识遗忘</strong>和<strong>重复训练</strong>的痛点，是一个更具工程实践价值和学术挑战性的方向。</p>
<ul>
<li><p><strong>价值与意义：</strong> 现实世界的TKG是持续演化的，例如新的科研项目会不断立项、结项。每次有新事实加入，如果需要<strong>从头训练</strong>模型，会造成巨大的<strong>计算开销</strong>和<strong>时间成本</strong>。该选题研究如何让模型在<strong>增量</strong>数据上高效学习新知识，同时<strong>不遗忘</strong>旧知识，这对于构建一个实时、动态的科研管理预测系统至关重要。</p>
</li>
<li><p><strong>创新点：</strong></p>
<ol>
<li><p><strong>持续学习框架：</strong> 构建一个<strong>持续学习</strong>（Continual Learning）框架，允许模型在接收新的时间快照时进行<strong>增量更新</strong>，而非从头训练。</p>
</li>
<li><p><strong>知识蒸馏与回放机制：</strong> 引入<strong>知识蒸馏</strong>和<strong>经验回放</strong>等技术，解决增量学习中的<strong>灾难性遗忘</strong>问题，确保模型在学习新知识的同时，能够保留对历史知识的理解。</p>
</li>
<li><p><strong>LLM与增量嵌入：</strong> 结合LLM的<strong>语义记忆</strong>和TKG的<strong>增量嵌入</strong>技术。LLM可以为新实体提供零样本的初始表示，而增量嵌入模块则负责将其与现有知识图谱的表示进行融合。</p>
</li>
</ol>
</li>
<li><p><strong>贡献：</strong></p>
<ol>
<li><p>为解决TKG在<strong>动态演化</strong>和<strong>持续更新</strong>场景下的<strong>知识遗忘</strong>问题提供了一套可行的解决方案。</p>
</li>
<li><p>提出了LLM在<strong>持续学习</strong>中的新应用，即作为<strong>语义记忆</strong>和<strong>冷启动</strong>工具。</p>
</li>
<li><p>为构建<strong>实时更新、高效</strong>的TKG预测系统奠定技术基础。</p>
</li>
</ol>
</li>
<li><p><strong>基线模型（Baseline）：</strong></p>
<ul>
<li><p><strong>TANGO (Han et al., 2021)：</strong> 一种基于ODE（常微分方程）的TKG模型，可以建模连续时间演化，但不支持增量学习。</p>
</li>
<li><p><strong>ONSEP (Wang et al., 2024)：</strong> 一种利用LLM进行在线、少样本TKG预测的方法。</p>
</li>
<li><p><strong>Recurrent Event Network (RE-NET)：</strong> 一种自回归模型，通过RNN编码历史快照，但当新快照到来时通常需要重新训练。</p>
</li>
</ul>
</li>
<li><p><strong>模型设计：</strong></p>
<ol>
<li><p><strong>模型一（基线增量学习）：</strong> 采用<strong>GNN + 持续学习</strong>的框架。每次有新的时间快照，模型通过<strong>正则化</strong>或<strong>经验回放</strong>机制进行小步长微调，避免对旧知识的遗忘。</p>
</li>
<li><p><strong>模型二（LLM增强的增量学习）：</strong> 在模型一的基础上，引入LLM。当出现新的、未见过的实体时，LLM可以根据其文本描述生成初始嵌入，作为GNN的输入，从而实现<strong>高效的冷启动</strong>。</p>
</li>
</ol>
</li>
<li><p><strong>数据集：</strong> 同前，但你的社科数据由于是项目管理流程数据，其<strong>持续性</strong>特性使得该选题更具说服力。</p>
</li>
<li><p><strong>实验设计：</strong></p>
<ul>
<li><p><strong>性能评估：</strong> 比较模型在<strong>增量学习</strong>模式下与<strong>从头训练</strong>模式下的<strong>Hits@k</strong>等指标差异，验证增量学习的有效性。</p>
</li>
<li><p><strong>遗忘度评估：</strong> 设计实验评估模型在新数据上训练后，在旧数据上的性能下降情况，量化<strong>灾难性遗忘</strong>程度。</p>
</li>
<li><p><strong>效率评估：</strong> 比较增量学习模式与从头训练模式的<strong>训练时间</strong>，验证其计算效率优势。</p>
</li>
</ul>
</li>
<li><p><strong>预期结论：</strong> 提出的增量学习框架能在保持较高预测准确性的同时，显著减少训练时间，有效解决知识遗忘问题，使其更适用于持续更新的动态数据场景。</p>
</li>
</ul>
<h3 id="少样本场景下基于LLM的TKG外推预测增强✅"><a href="#少样本场景下基于LLM的TKG外推预测增强✅" class="headerlink" title="少样本场景下基于LLM的TKG外推预测增强✅"></a>少样本场景下基于LLM的TKG外推预测增强✅</h3><p><strong>选题理由：</strong></p>
<ul>
<li><strong>价值意义</strong>：在科研管理中，稀疏数据（如少量项目历史）导致未来事件预测（如项目结项时间、奖励发放）困难。该选题可提升预测准确性，支持决策（如资源分配），并通用适用于其他动态领域（如医疗事件预测、社会事件预警），解决文档中“新事件&#x2F;实体预测能力不足”和“少样本学习”问题。</li>
<li><strong>创新点</strong>：结合LLM的零&#x2F;少样本提示学习与TKG的自回归方法，实现对稀疏数据的动态外推预测；引入时间感知提示模板，增强LLM对时间依赖的捕捉，超越传统方法对历史数据的过度依赖。</li>
<li><strong>贡献</strong>：提出一个通用框架，提升少样本TKG外推准确率10-20%；在科研管理数据集上验证实际应用，如预测项目变更事件；提供开源代码，促进领域发展。</li>
<li><strong>Baseline（近2年的）</strong>：GenTKG (Park et al., 2024) - 使用LLM进行TKG外推预测；zrLLM (Chen et al., 2023) - 零样本LLM推理框架；TGL-LLM (Xiong et al., 2024) - LLM与图模型融合。</li>
<li><strong>技术方案（可组合现有方法）</strong>：通用框架：(1) 数据预处理：将TKG表示为四元组序列；(2) LLM增强：使用提示工程（如“基于历史事件[历史序列]，预测未来[时间戳]的[实体-关系]”）结合zrLLM的零样本机制；(3) 融合自回归（如RE-NET的序列建模）与LLM输出，通过注意力机制加权时间依赖；(4) 优化：少样本微调LLM适配器。适用于多种场景，如事件预测或关系外推。</li>
<li><strong>数据集</strong>：公开：ICEWS18（训练验证外推预测）；自制：科研管理TKG（实体：项目&#x2F;机构&#x2F;人员；关系：申报&#x2F;立项&#x2F;变更；时间：流程时间戳），约1000-5000事实，用于应用验证。</li>
<li><strong>实验设计</strong>：(1) 基线比较：Hits@1&#x2F;3&#x2F;10、MRR vs. baselines；(2) Ablation：移除LLM&#x2F;自回归组件；(3) 少样本设置：训练集10%&#x2F;20%数据；(4) 应用验证：科研数据集上预测项目结项准确率；(5) 运行环境：PyTorch + HuggingFace LLM。</li>
<li><strong>预期结论</strong>：框架在少样本下优于baselines，提升外推准确性；科研管理应用中，可预测80%项目事件，支持决策。</li>
</ul>
<h3 id="基于LLM的可解释TKG内插补全在稀疏数据中的应用❌"><a href="#基于LLM的可解释TKG内插补全在稀疏数据中的应用❌" class="headerlink" title="基于LLM的可解释TKG内插补全在稀疏数据中的应用❌"></a>基于LLM的可解释TKG内插补全在稀疏数据中的应用❌</h3><p><strong>选题理由：</strong></p>
<ul>
<li><strong>价值意义</strong>：科研管理数据稀疏（如关系少），导致知识补全（如缺失人员-项目关系）不准。该选题提供可解释补全，提升透明度（如解释为什么补全某关系），适用于高风险决策场景（如奖励审核），解决文档中“黑盒模型问题”和“数据稀疏与冷启动”痛点。</li>
<li><strong>创新点</strong>：融合LLM的自然语言解释生成与TKG的逻辑规则方法，实现补全路径的可视化解释；设计时间敏感的规则提取模块，针对稀疏数据增强泛化。</li>
<li><strong>贡献</strong>：开发通用可解释框架，提高补全MRR 15%并提供解释覆盖率；应用于科研管理，如补全缺失成果关系；贡献解释评估指标（如解释忠实度）。</li>
<li><strong>Baseline（近2年的）</strong>：ICLTKG (2023) - LLM增强语义补全；ECOLA (2023) - LLM与TKG融合；TPRG (Park et al., 2023) - 逻辑规则外推。</li>
<li><strong>技术方案（可组合现有方法）</strong>：通用框架：(1) TKG表示：四元组补全任务；(2) LLM融合：用ICLTKG的语义增强提示生成候选事实；(3) 可解释模块：结合TPRG的规则学习提取时间路径（如“项目立项→变更→结项”），LLM生成NL解释；(4) 优化：链式推理确保解释一致性。适用于知识补全、问答等场景。</li>
<li><strong>数据集</strong>：公开：Wikidata (KR)（训练验证内插补全）；自制：科研管理TKG（稀疏关系补全，如人员-奖励缺失）。</li>
<li><strong>实验设计</strong>：(1) 性能：MR&#x2F;MRR&#x2F;Hits@k vs. baselines；(2) 可解释性：人工评估解释质量（覆盖率&#x2F;忠实度）；(3) 稀疏设置：移除20-50%事实模拟冷启动；(4) 应用：科研数据集补全率与解释验证。</li>
<li><strong>预期结论</strong>：框架在稀疏数据下提供高准确补全与可靠解释；科研应用中，补全90%缺失关系，提升管理效率。</li>
</ul>
<h3 id="LLM辅助的TKG实体对齐与推理在科研管理中的融合❌"><a href="#LLM辅助的TKG实体对齐与推理在科研管理中的融合❌" class="headerlink" title="LLM辅助的TKG实体对齐与推理在科研管理中的融合❌"></a>LLM辅助的TKG实体对齐与推理在科研管理中的融合❌</h3><p><strong>选题理由：</strong></p>
<ul>
<li><strong>价值意义</strong>：科研管理涉及多源数据（如不同机构的项目数据），实体对齐（如合并人员实体）困难。该选题提升对齐准确性，支持跨系统推理（如项目协作预测），解决文档中“实体覆盖率低”和“时间建模方法”问题，适用于异构知识整合场景。</li>
<li><strong>创新点</strong>：用LLM的语义相似度增强TKG实体对齐，结合时间注意力实现动态对齐；针对少样本，引入元学习适应稀疏数据。</li>
<li><strong>贡献</strong>：提出融合框架，提高对齐F1分数20%；在科研管理中验证，如对齐机构-项目实体；扩展到通用实体对齐任务。</li>
<li><strong>Baseline（近2年的）</strong>：TREA (2023) - 时序关系注意力对齐；STEA (2023) - 简单GNN时间匹配；TKG-LM (Han et al., 2023) - LLM图融合。</li>
<li><strong>技术方案（可组合现有方法）</strong>：通用框架：(1) 实体表示：TKG四元组嵌入；(2) LLM辅助：用TKG-LM的提示计算语义相似（如“实体A[描述]与B[描述]是否相同？”）；(3) 对齐融合：结合TREA的时间注意力聚合邻居；(4) 推理扩展：对齐后进行实体预测。适用于跨域对齐、融合推理。</li>
<li><strong>数据集</strong>：公开：DICEWS（训练验证实体对齐）；自制：科研管理TKG（多源实体，如不同数据库的人员对齐）。</li>
<li><strong>实验设计</strong>：(1) 对齐指标：Precision&#x2F;Recall&#x2F;F1 vs. baselines；(2) 推理性能：Hits@k post-对齐；(3) 少样本：训练5-10%对齐对；(4) 应用：科研数据集对齐准确率与推理验证。</li>
<li><strong>预期结论</strong>：框架提升对齐与推理效率；科研应用中，对齐95%实体，支持跨机构分析。</li>
</ul>
<h3 id="学习研究路线"><a href="#学习研究路线" class="headerlink" title="学习研究路线"></a>学习研究路线</h3><p>鉴于您无ML&#x2F;DL基础、仅1年时间，我为每个选题设计了一个紧凑路线（总时长约12个月，假设每周20-30小时）。路线从基础学习入手，逐步到实验，强调实践。</p>
<h4 id="通用前期准备（适用于所有选题，Month-1-2）："><a href="#通用前期准备（适用于所有选题，Month-1-2）：" class="headerlink" title="通用前期准备（适用于所有选题，Month 1-2）："></a>通用前期准备（适用于所有选题，Month 1-2）：</h4><ul>
<li><strong>Month 1</strong>: 学习Python基础（1周，Codecademy）；ML&#x2F;DL入门（2周，Andrew Ng Coursera课程）；TKG概念（1周，阅读调研文档+论文如TComplEx）。</li>
<li><strong>Month 2</strong>: LLM基础（1周，HuggingFace教程）；图神经网络入门（1周，PyG库教程）；实践：安装环境，运行简单TKG baseline（如RE-NET on ICEWS）。</li>
</ul>
<h4 id="针对选题1的路线（Month-3-12）："><a href="#针对选题1的路线（Month-3-12）：" class="headerlink" title="针对选题1的路线（Month 3-12）："></a>针对选题1的路线（Month 3-12）：</h4><ul>
<li><strong>Month 3-4 (文献与方案设计)</strong>: 阅读baselines (GenTKG等，2周)；设计框架（结合LLM提示+自回归，1周）；构建自制数据集（科研数据转TKG，1周）。</li>
<li><strong>Month 5-7 (模型实现)</strong>: 实现LLM部分（HuggingFace，2周）；融合自回归（PyTorch，2周）；调试少样本微调（2周）；初步测试公开数据集。</li>
<li><strong>Month 8-9 (实验与验证)</strong>: 运行实验（基线比较、ablation，3周）；应用自制数据集（2周）；分析结果（1周）。</li>
<li><strong>Month 10-11 (论文写作)</strong>: 撰写章节（模型设计、实验，4周）；迭代实验（2周）。</li>
<li><strong>Month 12 (收尾)</strong>: 完善论文、准备答辩（2周）；开源代码（1周）；如果时间紧，简化ablation。</li>
</ul>
<h4 id="针对选题2的路线（类似选题1，调整重点）："><a href="#针对选题2的路线（类似选题1，调整重点）：" class="headerlink" title="针对选题2的路线（类似选题1，调整重点）："></a>针对选题2的路线（类似选题1，调整重点）：</h4><ul>
<li><strong>Month 3-4</strong>: 重点阅读可解释论文（TPRG等）；设计解释模块。</li>
<li><strong>Month 5-7</strong>: 实现LLM解释生成+规则学习。</li>
<li>其余同选题1，强调可解释评估（人工标注）。</li>
</ul>
<h4 id="针对选题3的路线（类似选题1，调整重点）："><a href="#针对选题3的路线（类似选题1，调整重点）：" class="headerlink" title="针对选题3的路线（类似选题1，调整重点）："></a>针对选题3的路线（类似选题1，调整重点）：</h4><ul>
<li><strong>Month 3-4</strong>: 重点阅读对齐论文（TREA等）；设计对齐模块。</li>
<li><strong>Month 5-7</strong>: 实现LLM相似+时间注意力。</li>
<li>其余同选题1，强调对齐指标。</li>
</ul>
<p><strong>总体建议</strong>：每周阅读1-2论文；用GitHub管理代码；求助导师&#x2F;论坛；如果1年紧迫，优先一个模型，第二个简化。</p>
<ul>
<li><p><strong>第一阶段（1-3个月）：基础夯实与文献调研</strong></p>
<ol>
<li><strong>机器学习&#x2F;深度学习基础：</strong> 学习Python编程（PyTorch或TensorFlow）、线性代数、概率论、神经网络基础。可以通过在线课程（如吴恩达的机器学习课程）快速入门。</li>
<li><strong>图神经网络基础：</strong> 学习GNN基础概念（GCN, GAT），理解图数据如何建模和处理。可以阅读相关综述和入门教程。</li>
<li><strong>时间知识图谱基础：</strong> 深入阅读你提供的调研文档，理解核心概念（TKG定义、核心任务、评估指标）和现有方法（表示方法、补全&#x2F;预测方法）。</li>
<li><strong>大语言模型基础：</strong> 了解Transformer架构、LLM的原理（提示学习、上下文学习），并学会使用开源LLM（如Llama2，Mistral）进行简单任务。</li>
<li><strong>文献精读：</strong> 围绕你选择的选题，精读近2-3年发表在顶会（如NeurIPS, ICLR, KDD, WWW）上的核心论文，理解其方法、创新点和实验设计。</li>
</ol>
</li>
<li><p><strong>第二阶段（4-7个月）：模型设计与原型开发</strong></p>
<ol>
<li><strong>数据处理：</strong> 将你的社科管理数据进行清洗、格式化，并与公开数据集对齐，以便后续实验使用。</li>
<li><strong>模型一实现：</strong> 根据你选择的选题，实现第一个核心模型。由于是硕士阶段，可以从<strong>复现</strong>某篇经典论文的基线模型开始，逐步在其基础上加入你的<strong>创新点</strong>（如融合LLM）。</li>
<li><strong>实验验证：</strong> 在公开数据集上进行初步实验，验证模型性能是否符合预期。及时调整模型设计或超参数。</li>
<li><strong>问题调试与优化：</strong> 这个阶段会遇到很多技术难点，如梯度消失、模型不收敛等。需要多与导师沟通，多在论坛上寻求帮助。</li>
</ol>
</li>
<li><p><strong>第三阶段（8-10个月）：核心创新点实现与论文撰写</strong></p>
<ol>
<li><strong>模型二实现：</strong> 在模型一的基础上，实现第二个核心创新点（如针对少样本&#x2F;增量学习的改进）。</li>
<li><strong>深入实验：</strong> 在你的自制数据集上进行应用层面的验证，并进行详细的<strong>消融实验</strong>和<strong>可解释性分析</strong>。</li>
<li><strong>论文初稿：</strong> 边实验边撰写论文，包括绪论、相关工作、方法、实验等章节。</li>
</ol>
</li>
<li><p><strong>第四阶段（11-12个月）：论文完善与答辩准备</strong></p>
<ol>
<li><strong>论文修改：</strong> 根据导师的反馈，反复修改和完善论文。确保逻辑严谨、表述清晰。</li>
<li><strong>答辩准备：</strong> 准备PPT，梳理整个研究的思路、创新点和贡献。</li>
</ol>
</li>
</ul>
<table>
<thead>
<tr>
<th>阶段</th>
<th>时间</th>
<th>任务</th>
<th>学习与研究内容</th>
</tr>
</thead>
<tbody><tr>
<td><strong>基础入门</strong></td>
<td>1-2个月</td>
<td>补足机器学习和深度学习基础知识；初步熟悉TKG领域。</td>
<td><strong>机器学习&#x2F;深度学习</strong>：吴恩达《机器学习》、李宏毅《机器学习&#x2F;深度学习》视频课程，掌握基本概念、PyTorch&#x2F;TensorFlow框架。<br><strong>TKG</strong>：阅读综述（如附件中的调研结果），理解核心问题、方法和评估指标。</td>
</tr>
<tr>
<td><strong>选题深化与方案设计</strong></td>
<td>2-3个月</td>
<td>确定最终选题；详细设计技术方案、实验方案和论文大纲。</td>
<td>针对选定的题目，精读相关<strong>顶级会议论文</strong>（ACL, EMNLP, NeurIPS, KDD等）的最新研究，特别是2023-2024年的工作。</td>
</tr>
<tr>
<td><strong>代码实现与实验</strong></td>
<td>4-6个月</td>
<td>实现基线模型和您的创新模型；在公开数据集上进行实验。</td>
<td>学习并复现至少一个TKG的开源项目，例如<code>OpenKE</code>或相关GitHub代码库。逐步实现您设计的模型框架。</td>
</tr>
<tr>
<td><strong>数据处理与应用</strong></td>
<td>7-9个月</td>
<td>清洗和处理您的社科科研管理数据；在自制数据集上进行应用验证。</td>
<td>将您的数据转化为TKG通用格式（如<code>h, r, t, τ</code>四元组）。设计针对您的数据的具体任务和评估方式。</td>
</tr>
<tr>
<td><strong>论文撰写与总结</strong></td>
<td>10-12个月</td>
<td>撰写论文初稿；反复修改、完善，最终定稿。</td>
<td>按照论文大纲逐步撰写，确保逻辑严谨、论证充分。</td>
</tr>
</tbody></table>
<h3 id="毕业论文大纲（思维导图格式）"><a href="#毕业论文大纲（思维导图格式）" class="headerlink" title="毕业论文大纲（思维导图格式）"></a>毕业论文大纲（思维导图格式）</h3><p>以下用文本模拟思维导图（树状结构），论文包含6个核心章节。模型1与2紧密联系：模型1针对数据稠密场景（公开数据集），模型2针对数据稀疏少样本场景（自制数据集），模型2基于模型1的框架扩展少样本适应（如添加元学习）。假设基于选题1（可替换其他）。</p>
<ul>
<li><strong>根节点: 少样本场景下基于LLM的TKG外推预测增强研究</strong><ul>
<li><strong>1. 绪论</strong><ul>
<li>1.1 研究背景与意义</li>
<li>1.2 研究问题与目标</li>
<li>1.3 研究内容与创新点</li>
<li>1.4 论文结构</li>
</ul>
</li>
<li><strong>2. 相关理论及技术概述</strong><ul>
<li>2.1 TKG基础（定义、问题、方法）</li>
<li>2.2 LLM在TKG中的应用</li>
<li>2.3 少样本学习与外推预测</li>
<li>2.4 现有研究局限性</li>
</ul>
</li>
<li><strong>3. 第1个模型设计与实现（基于核心创新点1: LLM增强的自回归外推框架，针对数据稠密场景）</strong><ul>
<li>3.1 模型概述（框架结构）</li>
<li>3.2 核心组件（LLM提示 + 自回归序列建模）</li>
<li>3.3 算法实现（伪代码、优化）</li>
<li>3.4 实验验证（公开数据集结果）</li>
</ul>
</li>
<li><strong>4. 第2个模型设计与实现（基于核心创新点2: 少样本适应扩展，针对数据稀疏场景）</strong><ul>
<li>4.1 模型扩展（基于模型1添加少样本微调适配器）</li>
<li>4.2 核心组件（时间感知提示 + 元学习优化）</li>
<li>4.3 算法实现（与模型1联系：共享嵌入层）</li>
<li>4.4 实验验证（自制数据集应用）</li>
</ul>
</li>
<li><strong>5. 实验设计与结果分析</strong> (注: 用户指定6章节，但思维导图可整合实验到模型章；若需独立，此为额外)<ul>
<li>5.1 整体实验设置</li>
<li>5.2 性能比较与ablation</li>
<li>5.3 应用案例分析</li>
</ul>
</li>
<li><strong>6. 总结与展望</strong><ul>
<li>6.1 研究总结与贡献</li>
<li>6.2 局限性</li>
<li>6.3 未来工作</li>
</ul>
</li>
</ul>
</li>
</ul>
<figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><code class="hljs angelscript">毕业论文大纲<br>├── <span class="hljs-number">1.</span> 绪论<br>│   ├── <span class="hljs-number">1.1</span> 研究背景与意义<br>│   │   ├── 动态知识图谱的挑战<br>│   │   └── 少样本/增量学习在现实世界的应用需求<br>│   ├── <span class="hljs-number">1.2</span> 国内外研究现状<br>│   │   └── 现有TKG补全/预测方法、LLM在KG中的应用<br>│   ├── <span class="hljs-number">1.3</span> 主要研究内容与贡献<br>│   │   ├── 核心创新点概述<br>│   │   └── 本文的理论和应用价值<br>│   └── <span class="hljs-number">1.4</span> 论文组织结构<br>├── <span class="hljs-number">2.</span> 相关理论与技术概述<br>│   ├── <span class="hljs-number">2.1</span> 时序知识图谱基础<br>│   │   └── TKG定义、表示、核心问题与任务<br>│   ├── <span class="hljs-number">2.2</span> 知识图谱表示学习<br>│   │   └── 经典方法（TransE, ComplEx）与时序扩展<br>│   ├── <span class="hljs-number">2.3</span> 图神经网络（GNN）<br>│   │   └── GCN, GAT等基本原理<br>│   ├── <span class="hljs-number">2.4</span> 大语言模型（LLM）<br>│   │   └── Transformer, 提示学习, 上下文学习<br>│   └── <span class="hljs-number">2.5</span> 持续学习/少样本学习<br>│       └── 核心概念、挑战与解决方案<br>├── <span class="hljs-number">3.</span> 模型设计与实现（基于核心创新点<span class="hljs-number">1</span>）<br>│   ├── <span class="hljs-number">3.1</span> 选题<span class="hljs-number">1</span>：融合LLM与TKG的少样本预测模型（或选题<span class="hljs-number">2</span>/<span class="hljs-number">3</span>）<br>│   ├── <span class="hljs-number">3.2</span> 总体模型架构<br>│   │   └── 模块化设计（数据编码、LLM增强、GNN推理）<br>│   ├── <span class="hljs-number">3.3</span> 核心模块设计<br>│   │   ├── LLM语义增强模块<br>│   │   └── 时间感知的GNN编码器<br>│   └── <span class="hljs-number">3.4</span> 损失函数与训练策略<br>│       └── 针对少样本/稀疏数据的优化<br>├── <span class="hljs-number">4.</span> 模型设计与实现（基于核心创新点<span class="hljs-number">2</span>）<br>│   ├── <span class="hljs-number">4.1</span> 选题<span class="hljs-number">1</span>：可解释性增强模块（或选题<span class="hljs-number">2</span>/<span class="hljs-number">3</span>）<br>│   ├── <span class="hljs-number">4.2</span> 核心模块设计<br>│   │   ├── 基于LLM的推理路径生成<br>│   │   └── 注意力机制或强化学习的归因方法<br>│   └── <span class="hljs-number">4.3</span> 实验验证<br>│       └── 可解释性评估、定性与定量分析<br>├── <span class="hljs-number">5.</span> 实验与分析<br>│   ├── <span class="hljs-number">5.1</span> 数据集介绍<br>│   │   ├── 公开数据集（ICEWS18/GDELT）<br>│   │   └── 自制科研管理数据集<br>│   ├── <span class="hljs-number">5.2</span> 实验设置与评估指标<br>│   │   └── MRR, <span class="hljs-symbol">Hits@</span>k, MR等<br>│   ├── <span class="hljs-number">5.3</span> 实验结果与对比分析<br>│   │   ├── 与基线模型的性能对比<br>│   │   └── 消融实验结果分析<br>│   └── <span class="hljs-number">5.4</span> 案例分析<br>│       └── 在社科管理数据上的具体应用案例<br>├── <span class="hljs-number">6.</span> 总结与展望<br>│   ├── <span class="hljs-number">6.1</span> 本文工作总结<br>│   │   └── 再次强调主要贡献与创新点<br>│   ├── <span class="hljs-number">6.2</span> 存在的问题与未来工作<br>│   │   └── 模型局限性、可扩展性等<br>│   └── <span class="hljs-number">6.3</span> 论文总结<br></code></pre></td></tr></table></figure>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E7%A7%91%E7%A0%94%E5%AD%A6%E4%B9%A0/" class="category-chain-item">科研学习</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div></div>
      <div>https://alleyf.github.io/2025/09/124e5eddb410.html</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>alleyf</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2025年9月22日</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>更新于</div>
          <div>2025年9月22日</div>
        </div>
      
      <div class="license-meta-item">
        <div>许可协议</div>
        <div>
          
            
            
              <a target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
              <span class="hint--top hint--rounded" aria-label="BY - 署名">
                <i class="iconfont icon-by"></i>
              </span>
              </a>
            
          
        </div>
      </div>
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2025/09/4e4910ce215c.html" title="​《历史链推理：让LLM像侦探一样破解时序知识图谱！高阶信息+分步推理=预测开挂》">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">​《历史链推理：让LLM像侦探一样破解时序知识图谱！高阶信息+分步推理=预测开挂》</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2025/09/2b5f8440eeae.html" title="基于 LLM 的少样本时序知识图谱推理与可解释性增强研究">
                        <span class="hidden-mobile">基于 LLM 的少样本时序知识图谱推理与可解释性增强研究</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
  <article id="comments" lazyload>
    
  <div id="gitalk-container"></div>
  <script type="text/javascript">
    Fluid.utils.loadComments('#gitalk-container', function() {
      Fluid.utils.createCssLink('/css/gitalk.css')
      Fluid.utils.createScript('https://lib.baomitu.com/gitalk/1.7.2/gitalk.min.js', function() {
        var options = Object.assign(
          {"clientID":"636f2864e051a199b91c","clientSecret":"5185fd11115bbcd8d2f636bc80de6bed98ed14c1","repo":"Gitalk","owner":"Alleyf","admin":["Alleyf"],"language":"zh-CN","labels":["Gitalk"],"perPage":10,"pagerDirection":"last","distractionFreeMode":false,"createIssueManually":false,"proxy":"https://shielded-brushlands-08810.herokuapp.com/https://github.com/login/oauth/access_token"},
          {
            id: 'd0cb6e0381f82bca6985cae274738a49'
          }
        )
        var gitalk = new Gitalk(options);
        gitalk.render('gitalk-container');
      });
    });
  </script>
  <noscript>Please enable JavaScript to view the comments</noscript>


  </article>


          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  





  <script>
  Fluid.utils.createScript('https://lib.baomitu.com/mermaid/8.14.0/mermaid.min.js', function() {
    mermaid.initialize({"theme":"default"});
  });
</script>






    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://github.com/Alleyf" target="_blank" rel="nofollow noopener"><span>Alleyf</span></a> <i class="iconfont icon-love"></i> <a href="https://fcsy.fit" target="_blank" rel="nofollow noopener"><span>Homepage</span></a> 
    </div>
  
  
    <div class="statistics">
  
  

  
    
      <span id="busuanzi_container_site_pv" style="display: none">
        总访问量 
        <span id="busuanzi_value_site_pv"></span>
         次
      </span>
    
    
      <span id="busuanzi_container_site_uv" style="display: none">
        总访客数 
        <span id="busuanzi_value_site_uv"></span>
         人
      </span>
    
    
  
</div>

  
  
    <!-- 备案信息 ICP for China -->
    <div class="beian">
  <span>
    <a href="http://beian.miit.gov.cn/" target="_blank" rel="nofollow noopener">
      陕ICP备2022010038号
    </a>
  </span>
  
    
      <span>
        <a
          href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=2022010038"
          rel="nofollow noopener"
          class="beian-police"
          target="_blank"
        >
          
            <span style="visibility: hidden; width: 0">|</span>
            <img src="http://qnpicmap.fcsluck.top/pics/202311161820757.png" srcset="/img/loading.gif" lazyload alt="police-icon"/>
          
          <span>陕公网安备2022010038号</span>
        </a>
      </span>
    
  
</div>

  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      headingSelector : CONFIG.toc.headingSelector || 'h1,h2,h3,h4,h5,h6',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      collapseDepth   : CONFIG.toc.collapseDepth || 0,
      scrollSmooth    : true,
      headingsOffset  : -boardTop
    });
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.10/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        if (!window.MathJax) {
          window.MathJax = {
            tex    : {
              inlineMath: { '[+]': [['$', '$']] }
            },
            loader : {
              load: ['ui/lazy']
            },
            options: {
              renderActions: {
                insertedScript: [200, () => {
                  document.querySelectorAll('mjx-container').forEach(node => {
                    let target = node.parentNode;
                    if (target.nodeName.toLowerCase() === 'li') {
                      target.parentNode.classList.add('has-jax');
                    }
                  });
                }, '', false]
              }
            }
          };
        } else {
          MathJax.startup.document.state(0);
          MathJax.texReset();
          MathJax.typeset();
          MathJax.typesetPromise();
        }
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.1/es5/tex-mml-chtml.js" ></script>

  <script  src="/js/local-search.js" ></script>

  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
<!-- hexo injector body_end start --><script src="/assets/mmedia/mmedia-loader.js"></script><!-- hexo injector body_end end --></body>
</html>
